# Welcome to the ADS - Environment Repository!

In this repository you can find all the codes and information to do everything explained in this [ overleaf document](https://www.overleaf.com/read/swkhjmdypdrh).

There are several groups of documents in this repository: information, main codes and assisting codes. And the main codes are divided into the ones useful to find the weights, the ones to do reinforcement learning and the ones to analyse the results.

In order:
- **Policies old:** old policies that just my Diogenes syndrome doesn't let me get rid of.
- **Runs:** when generalizing to find proper parameters that could make the agent train correctly in any circumstances I saved here the outputs to understand how it was going.
1. **Videos:** recordings of the simulations. I recorded each policy with 10 episodes to showcase the behaviour under different pedestrian actions.
- **Celeste results:** documents for a colleague who needed some of the information from these runs.
2. **new_38_31:** A folder with the policies corresponding to a situation where the pedestrians start at the cells 38 and 31.
3. **new_45_31:** A folder with the policies corresponding to a situation where the pedestrians start at the cells 45 and 31.
4. **new_more_sto:** A folder with the policies corresponding to a situation where the pedestrians start at the cells 45 and 31. These policies are also ran under a more stochastic environment (hence, the name).
5. **numbers:** a folder with *.numbers (excel for apple) documents regarding the follow-up of the different policies and their learning. In each of the different scenarios, the steps to reach the proper weights and the values for the learning are documented to understand the behaviour of the algorithms.
6. **ADS_Environment.py:** a 
7. **CHVI.py:** 
8. **CHVI_aprox.py:** 
9. **ItemAndAgent.py:**
